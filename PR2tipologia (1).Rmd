---
title: "Práctica 2: Limpieza y análisis de datos"
date: "Enero 2023"
author: "Autores: Iñaki y Jesús"
output:
  html_document: 
    number_sections: true
    theme: cosmo
    toc: true
    toc_depth: 2
  word_document: default
  pdf_document: 
    highlight: zenburn
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1.Descripción del dataset

Para la realización de la práctica hemos elegido la base de datos que se propone en el enunciado de la actividad y que se titula ¨Heart Attack Analysis & Prediction Dataset". Los datos han sido descargados desde el repositorio Kaggle: <https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset?select=heart.csv>. Esta base de datos recoge distintos parámetros relacionados con la salud cardiovascular de multitud de individuos. 

El objetivo de nuestro proyecto es comprender los factores que influyen en la salud cardiovascular de las personas y así poder evitar problemas cardíacos en la población. Concretamente, nos interesa analizar aquellos parámetros que se puedan obtener mediante un análisis de sangre y un tensiómetro.

# 2.Selección de los datos

En el repositorio desde donde hemos descargado la base de datos se ofrece un diccionario con información sobre las variables que se han recogido en la base de datos. Las variables son las siguientes:

**age**: Edad del individuo (cuantitativa).

**sex**: Sexo del individuo. 0=mujer, 1=hombre (cualitativa).

**cp**: tipo de dolor de pecho. 1=típico, 2=atípico, 3=no anginoso, 4=asintomático.(cualitativa)

**trtbps**: presión sanguínea en reposo en mmHg (cuantitativa).

**chol**: niveles de colesterol en mg/dL (cuantitativa).

**fbs**: niveles de azúzar en sangre mayores de 120mg/dL. 0=negativo, 1=positivo.(cualitativa)

**restecg**: resultado del electrocardiograma en reposo. 0=normal, 1=onda ST-T anormal, 2=hipertrofia del ventrículo izquierdo. (cualitativa)

**thalachh**: frecuencia cardíaca máxima (cuantitativa).

**exng**: angina inducida por ejercicio. 0=no, 1=sí. (cualitativa)

**oldpeak**: Disminución del segmento ST inducida por ejercicio (cuantitativa).

**slp**:: pendiente del segmento ST. 1=ascendente, 2=plana, 3=descendente. (cualitativa)

**caa**: número de vasos mayores (cualitativa).

**thall**: padece talasemia. 0=desconocido, 1=no reversible, 2=normal, 3=reversible.(cualitativa)

**output**: probabilidad de sufrir un infarto. 0=baja, 1=alta. (cualitativa)

Entre todas las variables que se recogen nos interesan aquellas que sean parámetros analíticos de la sangre o de presión sanguínea, así como la edad y el sexo de los individuos. Además, seleccionaremos también la variable output, que etiqueta cada registro en función de la probabilidad de padecer un infarto. 

```{r message= FALSE, warning=FALSE}
#Cargamos los datos y comprobamos que están incluídas todas las variables
datos<-read.csv("heart.csv",header=T,sep=",")
str(datos)
#Seleccionamos las variables que nos interesan para el análisis
variables<-c(1,2,4,5,6,13,14)
data<-datos[variables]
```

# 3.Limpieza de los datos

La preparación y limpieza de los datos es una fase crítica en un proyecto de minería. Para comenzar, vamos a comprobar el número de registros y el tipo de cada una de las variables que hemos seleccionado.

```{r message= FALSE, warning=FALSE}
str(data)
```

La base de datos está compuesta por las variables que hemos seleccionado anteriormente e incluye 303 registros. Todas las variables son numéricas o están codificadas numéricamente (en el caso de las cualitativas).Para trabajar correctamente con las variables categóricas las convertimos en factores:

```{r message= FALSE, warning=FALSE}
if(!require(dplyr)){
    install.packages('dplyr', repos='http://cran.us.r-project.org')
    library(dplyr)
}
#Convertimos las variables cualitativas en factores
data2 <- data %>% mutate(across(c(2,5,6,7),factor))
str(data2)
```

## Elementos vacíos:

El siguiente paso es comprobar si existen valores nulos o elementos vacíos:

```{r message= FALSE, warning=FALSE}
#Comprobamos la presencia de valores nulos
colSums(is.na(data))
summary(data2)
```

Como hemos comprobado, no hay elementos nulos (NA) en el conjunto de datos. Aprovechamos el resultado de la función summary() para realizar un análisis descriptivo de los datos. En este resumen de las variables podemos ver los valores medios de los parámetros cuantitativos, así como el máximo y el mínimo de cada uno. Por ejemplo, los individuos incluidos en la base de datos tienen una edad media de 55 años, una mínima de 29 años y una máxima de 77 años. También podemos extraer información de las variables cualitativas. En relación al sexo de la muestra, se recogieron datos de 96 mujeres y 207 hombres. ADemás, comprobamos que estas variables no presentan ningún valor incorrecto, es decir, que no se corresponda con alguno de los que deben tomar. Esta función proporciona una información útil, sin embargo, no nos permite analizar la distribución de las variables numéricas. Para ello, realizamos una inspección visual representándolas en histogramas:

```{r message= FALSE, warning=FALSE}
if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(Rmisc)){
    install.packages('Rmisc', repos='http://cran.us.r-project.org')
    library(Rmisc)
}
index<-c(1,3,4)
numericas<-colnames(data2[,index])
drawhist<- data2 %>% select(all_of(numericas))
histList<-list()
for(y in 1:ncol(drawhist)){
  col <- names(drawhist)[y]
  ggp <- ggplot(drawhist, aes_string(x = col)) +
    geom_histogram(bins =30, fill = "cornflowerblue", color = "black")
  histList[[y]] <- ggp
}
multiplot(plotlist = histList, cols = 1)

```

En el análisis visual de los histogramas para cada variables podemos ver cómo se distribuyen los datos. Mientras que la edad y los niveles de colesterol parecen distribuirse de manera normal, aunque el colesterol tiene aspecto de campana asimétrica con valores alejados en uno de los lados, los valores de presión no parecen tener una distribución normal.

## Valores extremos:

Después del análisis visual de la distribución de las variables, analizamos la presencia de outliers o valores extremos. Para ello, representamos las variables cuantitativas en diagramas de cajas. En estas representaciones los valores que se dibujan como puntos son determinados como posibles outliers. Por defecto, el criterio para ser outlier es:

-   Por el límite superior: 3Q+1,5\*RIC
-   Por el límite inferior: 1Q-1,5\*RIC

```{r message= FALSE, warning=FALSE}
outbp<-boxplot(data2[,index], las=2, main="Análisis de outliers")
```

En el diagrama de cajas podemos ver que se han dibujado varios puntos en las variables trtbps y chol. Sin embargo, tenemos que decidir si estos valores pueden haber sido producidos por un error o son correctos. En el caso de la variable trtbps, que representa presión sanguínea, el valor máximo es 200. Como este valor puede ser correspondiente a un valor de presión, es un valor plausible y decidimos mantenerlo. En el caso de la variable chol, que recoge los niveles de colesterol, hay valores alrededor de 400 y uno máximo de 564. Igual que anteriomente, **aunque estos valores son muy altos podrían ser niveles reales por lo que los mantenemos**.

```{r message= FALSE, warning=FALSE}
#Guardamos la tabla con los datos limpios
write.csv(data2, file = "heartDataCleaned.csv", row.names = FALSE)
```

# 4.Análisis de los datos

Para realizar el análisis de los datos aplicamos distintas aproximaciones empleando las variables que hemos seleccionado previamente. En resumen, los análisis que vamos a realizar son:

- **Contraste de hipótesis** entre las variables chol y output.

- **Regresión lineal simple**  entre las variables age y chol.

- **Regresión lineal múltiple** entre las variables chol, age, trtbps.

- **Contraste de hipótesis** entre las variables trtbps y output.

- **Contraste de hipótesis** entre las variables trtbps y output.




## Análisis de normalidad y homocedasticidad

Antes de realizar los análisis es necesario comprobar la normalidad y homocedasticidad de las variables, ya que esto determinará la prueba estadística que emplearemos. Para analizar si las varaibles cuantitativas siguen una distribución normal empleamos el test de Shapiro-Wilk. 

El test de normalidad Shapiro-Wilk trabaja con la hipótesis nula de que los datos siguen una distribución normal. Valores del estadístico p inferiores al nivel de significancia permiten rechazar la hipótesis nula y, por lo tanto, llevarían a descartar la normalidad de los datos.

```{r message= FALSE, warning=FALSE}
attach(data2)
shapiro.test(age)
shapiro.test(trtbps)
shapiro.test(chol)
```

Ya que en los tres casos el valor p es menor de 0,05 (al asumir un error del 5%), entonces se rechaza la hipótesis nula  y se considera que los datos de las variables age, trtbps y chol no están distribuídos normalmente. 

En el caso de que las variables fueran paramétricas a continuación debería de analizarse la igualdad de varianzas. Sin embargo, ya que ninguna no sigue una distribución normal no es necesario realizar esta prueba. 

## Aplicación de pruebas estadísticas

- **Regresión lineal simple**

El análisis de regresión lineal se utiliza para predecir el valor de una variable en función del valor de otra. La variable que se desea predecir se denomina variable dependiente, mientras que la variable que se usa para predecir el valor de la otra variable se denomina variable independiente. En este caso, se quieren predecir los niveles de colesterol a partir de la edad.

Se quiere comprobar si existe una relación significativa entre las variables colesterol y edad a un nivel de significancia de 0,05. Para llevar a cabo este análisis estadístico, no es necesario que los datos de las variables estén distribuidos normalmente.

Antes de construir el modelo, vamos a crear unas gráficas para ver la relación entre la variable dependiente respecto a la independiente.

```{r}
plot(x = data2$age, y = data2$chol)
```

Procedemos a hacer la regresión lineal simple:

```{r}
lmSimple <- lm(age ~ chol, data = data2)
summary(lmSimple)
```

El coeficiente R² es 0.045, un valor muy bajo. Este coeficiente nos indica la proporción de la variabilidad total que explica el modelo, o qué tan bien se ajusta el modelo a los datos. En este caso, es un valor muy bajo, lo cual nos indica que la calidad del modelo es muy mala. Dicho de otra manera, el modelo solamente explica el 4,5% de la variación de los datos.

- **Regresión lineal múltiple**

La regresión lineal múltiple se utiliza para predecir el valor de una variable dependiente a partir de varias variables independientes.

En este caso, se van a usar las variables chol y age para predecir la variable trtbps Se quiere estudiar si las variables chol y age influyen en trtbps.

Antes de crear el modelo, vamos a estudiar la relación de las variables independientes respecto a la dependiente.

```{r}
plot(x = data2$trtbps, y = data2$age)
```

No apreciamos que la variable age tenga demasiada influencia en la variable trtbps.

```{r}
plot(x = data2$trtbps, y = data2$chol)
```

Tampoco apreciamos que la variable chol tenga demasiada influencia sobre la variable trtbps.

Vamos a construir el modelo de regresión lineal múltiple,

```{r}
modelo_regresion_multiple <- lm(data$trtbps ~ data$age + data$chol)
summary(modelo_regresion_multiple)
```

Como el valor p de la variable age es mucho menor que 0.05, rechazamos la hipótesis nula de que β = 0. Por tanto, existe una relación significativa entre las variables age y trtbps.

El valor p de la variable chol es mayor que 0,05. Por tanto, no podemos rechazar la hipótesis nula y concluimos que no existe una relación significativa entre las variable chol y trtbps.

También hay que destacar que el coeficiente R² es muy bajo, por lo que concluimos que este modelo de regresión lineal múltiple no es muy adecuado para hacer predicciones.

- **Contraste de hipótesis**

Queremos comprobar si existen diferencias significativas en el valor de chol entre los pacientes que han sufrido infartos y los que no han sufrido infartos con un nivel de confianza del 95%.

**Hipótesis nula y alternativa**

H0: la media de chol de los sujetos que tienen poca probabilidad de padecer infarto es igual a la media de chol de los sujetos que tienen altas probabilidades de padecer infarto.

H1: la media de chol de los sujetos que tienen altas probabilidades de padecer infarto es mayor a la media de chol de los sujetos que tienen poca probabilidad de padecer infarto.

**Aplicación del test**

Se va a emplear el test no paramétrico Wilcoxon, ya que las variables en cuestión no tienen una distribución normal. Debido al tamaño reducido de las muestras, no podemos asumir normalidad por el teorema del límite central. Es un test de dos muestras independientes sobre la media con varianzas desconocidas. El test va a ser bilateral.

```{r message= FALSE, warning=FALSE}
if(!require(car)) {
  install.packages('car',repos='http://cran.us.r-project.org')
  library(car)
}
#Comprobamos la igualdad de varianzas
leveneTest(data$chol,data$output)
wilcox.test(chol ~ output, data = data2)
```

**Interpretación de resultados**

Como el valor de p es menor que el nivel de confianza p < 0.05, rechazamos la hipótesis nula. Por tanto, concluimos que la media de colesterol en pacientes que tienen altas probabilidades de padecer infarto es distinta a la media de colesterol en pacientes que tienen bajas probabilidades de padecer infarto. 

****

**Hipótesis nula y alternativa**

Al igual que en la comparación anterior, la hipótesis nula de estos análisis afirma la igualdad de las distribuciones de las variables en cuestión. En el caso opuesto, las variables tienen distribuciones distintas y no están relacionas. 

**Aplicación del test e interpretación de los resultados**

```{r message= FALSE, warning=FALSE}
tabla1 <- table(data2$fbs, data2$output)
chisq.test(tabla1)

tabla2 <- table(data2$thall, data2$output)
chisq.test(tabla2)
```

En la primera comparación, realizada entre los niveles de azúcar y la probabilidad de padecer un infarto, el valor p tiene un valor de 0,744, por lo que no se rechaza la hipótesis nula y no hay diferencias significativas ni relación significanes en las dos variables.

En la última comparación, entre padecer talasemia y la probabilidad de tener un accidente vascular, el valor del estadístico p es menor de 0,05%. De esta manera, se rechaza la hipótesis nula y se puede afirmar que existe una relaciñon entre las variables. 


# 5.Resolución del problema

En el primer apartado hemos explicado que nuestro objetivo es comprender los factores que influyen en la salud cardiovascular de las personas y así poder evitar problemas cardíacos en la población. Concretamente, nos interesa analizar aquellos parámetros que se puedan obtener mediante un análisis de sangre y un tensiómetro.

Desafortunadamente, en general no hemos podido extraer todo el conocimiento que habíamos esperado a través de los análisis que hemos realizado. 

En el caso de la regresión lineal simple y múltiple, no hemos podido sacar ninguna conclusión porque los modelos no se ajustan lo suficiente a los datos.

El contraste de hipótesis sobre los niveles de chol y las posibilidades de padecer un infarto nos ha dado resultados que llaman la atención, ya que los altos niveles de colesterol normalmente se asocian con un mayor peligro de tener infartos o enfermedades cardiovasculares. Sería oportuno hacer más análisis con otro tipo de técnicas y datasets para contrastar estos resultados.

En cuanto al contraste de hipótesis de los niveles de azúcar y probabilidad de tener un infarto, podemos concluir que los niveles de azúcar no afectan al riesgo de padecer un infarto.

Por último, el contraste de análisis de la talasemia y probabilidad de tener un infarto nos indica que existe relación entre dichas variables. Por lo tanto, los pacientes que padecen la talasemia deberían de tener en cuenta que tienen más probabilidades de padecer un infarto.

# 6.Contribuciones al trabajo


|        Contribuciones        |  Firma  |
| ---------------------------- | ------- |
| Investigación previa         | JR, IA  |
| Redacción de las respuestas  | JR, IA  |
| Desarrollo del código        | JR, IA  |
| Participación en el vídeo    | JR, IA  |

